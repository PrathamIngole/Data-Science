{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056ecc11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13eb427b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prath\\FullStackDataScience\\Data-Science\\GenAI\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:25: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.2.12'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain_core\n",
    "langchain_core.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71131c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain_community\n",
    "langchain_community.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06471949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.7.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langsmith\n",
    "langsmith.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5527e65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.10'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c401cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in .\\.venv\\Lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in .\\.venv\\Lib\\site-packages (from langchain-community) (1.2.12)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in .\\.venv\\Lib\\site-packages (from langchain-community) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in .\\.venv\\Lib\\site-packages (from langchain-community) (2.0.46)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in .\\.venv\\Lib\\site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in .\\.venv\\Lib\\site-packages (from langchain-community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in .\\.venv\\Lib\\site-packages (from langchain-community) (3.13.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in .\\.venv\\Lib\\site-packages (from langchain-community) (9.1.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in .\\.venv\\Lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in .\\.venv\\Lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in .\\.venv\\Lib\\site-packages (from langchain-community) (0.7.3)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in .\\.venv\\Lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in .\\.venv\\Lib\\site-packages (from langchain-community) (2.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in .\\.venv\\Lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in .\\.venv\\Lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in .\\.venv\\Lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in .\\.venv\\Lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in .\\.venv\\Lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in .\\.venv\\Lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in .\\.venv\\Lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in .\\.venv\\Lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in .\\.venv\\Lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in .\\.venv\\Lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in .\\.venv\\Lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in .\\.venv\\Lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2.0 in .\\.venv\\Lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (26.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in .\\.venv\\Lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in .\\.venv\\Lib\\site-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\.venv\\Lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in .\\.venv\\Lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in .\\.venv\\Lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in .\\.venv\\Lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: xxhash>=3.0.0 in .\\.venv\\Lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.6.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in .\\.venv\\Lib\\site-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: anyio in .\\.venv\\Lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.12.1)\n",
      "Requirement already satisfied: certifi in .\\.venv\\Lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in .\\.venv\\Lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: idna in .\\.venv\\Lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in .\\.venv\\Lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\.venv\\Lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in .\\.venv\\Lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in .\\.venv\\Lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in .\\.venv\\Lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in .\\.venv\\Lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.venv\\Lib\\site-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.6.3)\n",
      "Requirement already satisfied: greenlet>=1 in .\\.venv\\Lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in .\\.venv\\Lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bc6197b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e711a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_groq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe488a7",
   "metadata": {},
   "source": [
    "### **Real LLM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "031387c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API keys are unique strings of characters that are used to authenticate and authorize access to a web API (Application Programming Interface). They are like passwords, but instead of being used to log in to a website, they are used to access specific data or services provided by the API.\n",
      "\n",
      "Here's how it works:\n",
      "\n",
      "1. A developer creates an account with a service provider (e.g., Google, Twitter, etc.) and requests an API key.\n",
      "2. The service provider generates a unique API key and provides it to the developer.\n",
      "3. The developer uses the API key in their application to make requests to the service provider's API.\n",
      "4. The API key is verified by the service provider, and if it's valid, the request is processed and the requested data or service is provided.\n",
      "\n",
      "API keys serve several purposes:\n",
      "\n",
      "1. **Authentication**: They verify the identity of the developer or application making the request.\n",
      "2. **Authorization**: They determine what actions the developer or application can perform (e.g., read-only access, write access, etc.).\n",
      "3. **Rate limiting**: They help prevent abuse by limiting the number of requests that can be made within a certain time frame.\n",
      "4. **Tracking**: They allow service providers to monitor usage and analytics.\n",
      "\n",
      "There are different types of API keys, including:\n",
      "\n",
      "1. **Public API keys**: Used for publicly accessible APIs, where the key is not sensitive and can be shared.\n",
      "2. **Private API keys**: Used for private APIs, where the key is sensitive and should not be shared.\n",
      "3. **OAuth tokens**: Used for authentication and authorization, especially in cases where users need to grant access to their data.\n",
      "4. **JSON Web Tokens (JWT)**: Used for authentication and authorization, especially in cases where a secure, stateless token is required.\n",
      "\n",
      "Best practices for using API keys include:\n",
      "\n",
      "1. Keeping them secure and not sharing them publicly.\n",
      "2. Using them only for the intended purpose.\n",
      "3. Rotating them regularly (e.g., every 90 days).\n",
      "4. Monitoring usage and analytics to detect potential abuse.\n",
      "\n",
      "In summary, API keys are essential for accessing web APIs and ensuring secure, authorized, and authenticated interactions between applications and services.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "groq_api_key = os.getenv(\"Groq_API_Key\")\n",
    "\n",
    "llm = ChatGroq(\n",
    "    api_key=groq_api_key,\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=None\n",
    ")\n",
    "llm\n",
    "question = \"What is api keys ?\"\n",
    "\n",
    "print(llm.invoke(question).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19873098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"API keys are unique strings or codes used to authenticate and authorize access to a specific Application Programming Interface (API). They serve as a secure way to identify the user, developer, or application making API requests, ensuring that only authorized parties can access the API's functionality and data.\\n\\nThink of an API key like a special password or token that grants access to a particular API. Here's how it works:\\n\\n**Why are API keys needed?**\\n\\n1. **Security**: API keys help protect the API from unauthorized access, abuse, or malicious activities.\\n2. **Authentication**: API keys verify the identity of the user or application making API requests.\\n3. **Authorization**: API keys determine the level of access and permissions granted to the user or application.\\n4. **Rate limiting**: API keys can be used to limit the number of requests made to an API, preventing abuse or overload.\\n\\n**How do API keys work?**\\n\\n1. **API key generation**: The API provider generates a unique API key for each user or application.\\n2. **API key registration**: The user or application registers the API key with the API provider.\\n3. **API request**: The user or application makes an API request, including the API key in the request header or query string.\\n4. **API key verification**: The API provider verifies the API key and checks the user's or application's permissions and access rights.\\n5. **API response**: If the API key is valid and the user or application has the required permissions, the API responds with the requested data or functionality.\\n\\n**Types of API keys**\\n\\n1. **Public API key**: A publicly available API key, often used for testing or development purposes.\\n2. **Private API key**: A private API key, only shared with authorized users or applications.\\n3. **OAuth token**: A token-based API key, used for authentication and authorization in OAuth-based APIs.\\n\\n**Best practices for using API keys**\\n\\n1. **Keep API keys secure**: Store API keys securely, and never expose them in public code or repositories.\\n2. **Use API keys with caution**: Only use API keys for their intended purpose, and avoid sharing them with unauthorized parties.\\n3. **Monitor API key usage**: Regularly monitor API key usage and revoke or update keys as needed.\\n\\nIn summary, API keys are essential for secure and authorized access to APIs, ensuring that only trusted users and applications can interact with the API's functionality and data.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 492, 'prompt_tokens': 40, 'total_tokens': 532, 'completion_time': 1.161224384, 'completion_tokens_details': None, 'prompt_time': 0.003213665, 'prompt_tokens_details': None, 'queue_time': 0.049083611, 'total_time': 1.164438049}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_dae98b5ecb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019c5ad4-5563-7591-a8db-6a3c30aeec7b-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 40, 'output_tokens': 492, 'total_tokens': 532}\n"
     ]
    }
   ],
   "source": [
    "question = question\n",
    "print(llm.invoke(question)) # without .content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ede10c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'is', 'api', 'keys', '?']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6eb9696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'llama-3.3-70b-versatile'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = llm.invoke(question)\n",
    "dir(ans)\n",
    "ans.response_metadata['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e53eae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 450,\n",
       "  'prompt_tokens': 40,\n",
       "  'total_tokens': 490,\n",
       "  'completion_time': 1.2671546089999999,\n",
       "  'completion_tokens_details': None,\n",
       "  'prompt_time': 0.001038702,\n",
       "  'prompt_tokens_details': None,\n",
       "  'queue_time': 0.049541893,\n",
       "  'total_time': 1.268193311},\n",
       " 'model_name': 'llama-3.3-70b-versatile',\n",
       " 'system_fingerprint': 'fp_c06d5113ec',\n",
       " 'service_tier': 'on_demand',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None,\n",
       " 'model_provider': 'groq'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = llm.invoke(question)\n",
    "dir(ans)\n",
    "ans.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bbb300",
   "metadata": {},
   "source": [
    "Structured Pormpt\n",
    "# provide brief explaination of Hypothesis testing and list its three main concepts in a single line.\n",
    "\n",
    "# topic =\"Hypothesis Testing\"\n",
    "# f'Porvide a brief explaination of {topic} and lits its three main concepts.in a single line'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a8ef203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Provide a brief explaination of {topic} and lists its three main concepts in a single line.')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "structured_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\"],\n",
    "    template=\"Provide a brief explaination of {topic} and lists its three main concepts in a single line.\"\n",
    ")\n",
    "structured_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617dd3f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7062fc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis testing is a statistical technique used to make inferences about a population based on a sample of data, and its three main concepts are: Null Hypothesis, Alternative Hypothesis, and Test Statistic.\n"
     ]
    }
   ],
   "source": [
    "chain = structured_prompt | llm\n",
    "inputs = {\"topic\" : \"Hypothesis testing\"}\n",
    "response = chain.invoke(inputs)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566e657b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb7969ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.chains'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[32m      2\u001b[39m LLMChain(llm = llm,prompt = structured_prompt).run(\u001b[33m'\u001b[39m\u001b[33mGenAI\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.chains'"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "LLMChain(llm = llm,prompt = structured_prompt).run('GenAI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fbbe06",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.chains'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[32m      2\u001b[39m LLMChain(llm = llm,prompt = structured_prompt).invoke(\u001b[33m'\u001b[39m\u001b[33mGenAI\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.chains'"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "LLMChain(llm = llm,prompt = structured_prompt).invoke('GenAI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0323d5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LLMChain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mLLMChain\u001b[49m(llm = llm,propmt = structured_prompt).invoke(\u001b[33m'\u001b[39m\u001b[33mTransformers\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'LLMChain' is not defined"
     ]
    }
   ],
   "source": [
    "LLMChain(llm = llm,propmt = structured_prompt).invoke('Transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd09ed7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'structured_prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m chain = \u001b[43mstructured_prompt\u001b[49m | llm\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(chain.invoke(\u001b[33m\"\u001b[39m\u001b[33mTransformers\u001b[39m\u001b[33m\"\u001b[39m).content)\n",
      "\u001b[31mNameError\u001b[39m: name 'structured_prompt' is not defined"
     ]
    }
   ],
   "source": [
    "chain = structured_prompt | llm\n",
    "print(chain.invoke(\"Transformers\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9a75df",
   "metadata": {},
   "source": [
    "### **Pipeline creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "107df1e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m chain = structured_prompt | llm | (\u001b[38;5;28;01mlambda\u001b[39;00m x:x.content)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMarvel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "chain = structured_prompt | llm | (lambda x:x.content)\n",
    "print(chain.invoke(\"Marvel\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7b4220",
   "metadata": {},
   "source": [
    "Parser\n",
    "Provide the clean output\n",
    "\n",
    "it is available in langchain_core\n",
    "\n",
    "the package name is langchain_core\n",
    "\n",
    "class: Out_Parsers\n",
    "\n",
    "Method name: StrOutParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf44f504",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StrOutParser' from 'langchain_core.output_parsers' (c:\\Users\\prath\\FullStackDataScience\\Data-Science\\GenAI\\.venv\\Lib\\site-packages\\langchain_core\\output_parsers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moutput_parsers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StrOutParser\n\u001b[32m      2\u001b[39m parser = StrOutParser()\n\u001b[32m      3\u001b[39m chain = structured_prompt | llm | parser\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'StrOutParser' from 'langchain_core.output_parsers' (c:\\Users\\prath\\FullStackDataScience\\Data-Science\\GenAI\\.venv\\Lib\\site-packages\\langchain_core\\output_parsers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutParser\n",
    "parser = StrOutParser()\n",
    "chain = structured_prompt | llm | parser\n",
    "print(chain.invoke(\"Linear Regression\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd7167d",
   "metadata": {},
   "source": [
    "## **Runnable Sequence**\n",
    "\n",
    "- I have two options\n",
    "    - Assume that based on my product I need to generate company name.\n",
    "        - Structured_prompt | llm | (lambda x:x.content)\n",
    "        - structured_prompt: Suggest a company name based on my healthcare product\n",
    "        - llm will take prompt and generate output \n",
    "        - .content will extract only specific output \n",
    "    - I want to generate a tag line based on my companu name \n",
    "        - structured_prmpt | llm | (lambda x:x)\n",
    "    - this is going in sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0ea179a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.10\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac32a1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some tagline options based on the company name suggestions:\n",
      "\n",
      "1. **MedBill Solutions**:\n",
      "\t* \"Simplifying healthcare billing, one invoice at a time.\"\n",
      "\t* \"Your partner in medical billing solutions.\"\n",
      "\t* \"Streamlining healthcare invoices for a healthier bottom line.\"\n",
      "2. **Healthcare Invoice Systems (HIS)**:\n",
      "\t* \"Efficient invoicing for a healthier healthcare system.\"\n",
      "\t* \"Innovating healthcare billing, one invoice at a time.\"\n",
      "\t* \"The backbone of healthcare billing, supporting your success.\"\n",
      "3. **CarePay Solutions**:\n",
      "\t* \"Caring for your financial health, one payment at a time.\"\n",
      "\t* \"Simplifying healthcare payments, for a healthier you.\"\n",
      "\t* \"Pay with ease, care with confidence.\"\n",
      "4. **MedInvoice Pro**:\n",
      "\t* \"Expert healthcare invoicing, at your fingertips.\"\n",
      "\t* \"Professional billing solutions, for a healthier practice.\"\n",
      "\t* \"Invoicing made easy, so you can focus on care.\"\n",
      "5. **BillingCare**:\n",
      "\t* \"Where billing meets care, and patients come first.\"\n",
      "\t* \"Caring for your billing needs, so you can care for your patients.\"\n",
      "\t* \"Billing with care, for a healthier healthcare system.\"\n",
      "6. **HealthBill Management**:\n",
      "\t* \"Managing your healthcare invoices, so you can manage your practice.\"\n",
      "\t* \"Simple, efficient, and effective billing solutions.\"\n",
      "\t* \"Your partner in healthcare billing management.\"\n",
      "7. **InvoiceMed**:\n",
      "\t* \"The medical billing solution you can trust.\"\n",
      "\t* \"Invoicing made easy, for a healthier medical practice.\"\n",
      "\t* \"Medically accurate invoicing, for a healthier bottom line.\"\n",
      "8. **CareInvoice Solutions**:\n",
      "\t* \"Caring for your patients, and your billing needs.\"\n",
      "\t* \"Invoicing with care, for a healthier healthcare system.\"\n",
      "\t* \"Simplifying healthcare billing, with care and compassion.\"\n",
      "\n",
      "Choose the one that resonates with your vision and values, or feel free to modify these suggestions to create a unique tagline that suits your needs.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "name_prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template = \"Provide a company name based on my {product}.\"\n",
    ")\n",
    "seq1 = name_prompt | llm | (lambda x:x.content)\n",
    "\n",
    "tag_line_prompt = PromptTemplate(\n",
    "    input_variables=[\"company_name\"],\n",
    "    template=\"Provide a tag line based on my {company_name}.\"\n",
    ")\n",
    "\n",
    "seq2 = tag_line_prompt | llm | (lambda x:x.content)\n",
    "\n",
    "Sequence = RunnableSequence(seq1,seq2)\n",
    "\n",
    "print(Sequence.invoke(\"Health care invoice details application.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a762132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some tagline suggestions based on the company name suggestions:\n",
      "\n",
      "1. **MedBill Solutions**: \"Streamlining healthcare billing, one invoice at a time.\"\n",
      "2. **HealthPay Systems**: \"Simplifying healthcare payments, for a healthier tomorrow.\"\n",
      "3. **CareInvoice Technologies**: \"Innovating invoice management, for better patient care.\"\n",
      "4. **MedClaims Pro**: \"Expert solutions for healthcare claims, every time.\"\n",
      "5. **WellBill Management**: \"Managing healthcare bills, for a healthier you.\"\n",
      "6. **Healthcare Revenue Solutions (HRS)**: \"Maximizing revenue, minimizing stress.\"\n",
      "7. **InvoiceCare**: \"Caring for your invoices, so you can care for your patients.\"\n",
      "8. **MediBill Systems**: \"Efficient billing, for a healthier practice.\"\n",
      "\n",
      "Alternatively, here are some more general tagline suggestions that could work for any of the company name suggestions:\n",
      "\n",
      "* \"Transforming healthcare billing, one invoice at a time.\"\n",
      "* \"Simplifying healthcare payments, for a healthier tomorrow.\"\n",
      "* \"Innovating invoice management, for better patient care.\"\n",
      "* \"Your partner in healthcare billing solutions.\"\n",
      "* \"Streamlining healthcare revenue, for a healthier practice.\"\n",
      "* \"Caring for your invoices, so you can care for your patients.\"\n",
      "* \"Efficient billing, for a healthier practice.\"\n",
      "* \"Expert solutions for healthcare claims and invoices.\"\n",
      "\n",
      "Let me know if you would like me to come up with more tagline suggestions or if you have any specific preferences (e.g. short and catchy, descriptive and informative, etc.)!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "name_prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template = \"Provide a company name based on my {product}.\"\n",
    ")\n",
    "seq1 = name_prompt | llm | (lambda x:x.content)\n",
    "\n",
    "tag_line_prompt = PromptTemplate(\n",
    "    input_variables=[\"company_name\"],\n",
    "    template=\"Provide a tag line based on my {company_name}.\"\n",
    ")\n",
    "\n",
    "seq2 = tag_line_prompt | llm | (lambda x:x.content)\n",
    "\n",
    "Sequence = RunnableSequence(seq1,seq2)\n",
    "\n",
    "dict1 = {'product': 'Healthcare invoice details application.'}\n",
    "print(Sequence.invoke(dict1))\n",
    "\n",
    "# print(Sequence.invoke(\"Health care invoice details application.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac148c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableSequence , RunnableParallel\n",
    "\n",
    "name_prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template = \"Provide a company name based on my {product}.\"\n",
    ")\n",
    "seq1 = name_prompt | llm | (lambda x:x.content)\n",
    "\n",
    "tag_line_prompt = PromptTemplate(\n",
    "    input_variables=[\"company_name\"],\n",
    "    template=\"Provide a tag line based on my {company_name}.\"\n",
    ")\n",
    "\n",
    "seq2 = tag_line_prompt | llm | (lambda x:x.content)\n",
    "\n",
    "Sequence = RunnableSequence(seq1,seq2)\n",
    "\n",
    "dict1 = {\n",
    "    \"Company Name\" : seq1,\n",
    "    \"Tag Name\" : seq2\n",
    "}\n",
    "\n",
    "\n",
    "parallel =  RunnableParallel()\n",
    "# print(Sequence.invoke(\"Health care invoice details application.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
